{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***@Cd2aProjeto***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @Cd2aProjeto\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'nubank'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nubank = pd.read_excel('nubank.xlsx', sep = ',')\n",
    "\n",
    "\n",
    "nubank.Treinamento = nubank.Treinamento.replace('_','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace(',','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('@','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('#','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('  ','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace(':','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('\"','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('rt','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('\\\\*','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('\\*','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('\\$','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('\\n','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('//','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace(';','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('/','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('\\(','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('\\)','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('\\'','',regex=True)\n",
    "nubank.Treinamento = nubank.Treinamento.replace('!','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separando colunas de Treinamento e Relevancia\n",
    "treina = pd.Series(np.sum(nubank.Treinamento + '').split())\n",
    "relev = pd.Series(np.sum(nubank.Relevancia + '').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separando tabelas de Treinamento e Relevancia\n",
    "data_relev = nubank[nubank.Relevancia == 'r']\n",
    "data_irrelev = nubank[nubank.Relevancia == 'ir']\n",
    "\n",
    "#Soma da tabela dos relevantas\n",
    "soma_relev = pd.Series(np.sum(data_relev.Treinamento + '').split())\n",
    "\n",
    "#Lista dos relevantes\n",
    "lista_relev = np.sum(data_relev.Treinamento+'').split()\n",
    "\n",
    "#Calculo do total dos relevantes\n",
    "total_relev = len(lista_relev)\n",
    "\n",
    "#Calculo do total dos irrelevantes\n",
    "soma_irrelev = pd.Series(np.sum(data_irrelev.Treinamento+'').split())\n",
    "\n",
    "#Lista dos irrelevantes\n",
    "lista_irrelev = np.sum(data_irrelev.Treinamento+'').split()\n",
    "\n",
    "#Calculo do total de irrelevantes\n",
    "total_irrelev = len(lista_irrelev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Função para calcular probabilidade de ser R ou I\n",
    "def bayes(lista):\n",
    "    lista = lista.split(' ')\n",
    "    prob_R = []\n",
    "    prob_I = []\n",
    "    for i in range(len(lista)):\n",
    "        prob_R.append((lista_relev.count(lista[i])+1)/(total_relev+len(lista)))\n",
    "        prob_I.append((lista_irrelev.count(lista[i])+1)/(total_irrelev+len(lista)))\n",
    "    \n",
    "    #Multiplica todos os fatores da lista\n",
    "    R = np.prod(prob_R)\n",
    "    I = np.prod(prob_I)\n",
    "    \n",
    "    if R>I:\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'ir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir <---  X  ---> r\n"
     ]
    }
   ],
   "source": [
    "#Testando função\n",
    "tweet_R = \"o odio q eu to do itaú....... eh agora q eu mudo pro nubank viu\"\n",
    "tweet_I = \"rt @nubankbrasil: diga olá para uma vida livre de dificuldades. peça seu cartão: https://t.co/n6igyi01pm https://t.co/a45pu21eov\"\n",
    "\n",
    "print(bayes(tweet_I) + ' <---  X  ---> ' +bayes(tweet_R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nubank = pd.read_excel('nubank.xlsx', sheetname = 'Teste', sep = ',')\n",
    "nubank['Maquina'] = ''\n",
    "\n",
    "nubank.Teste = nubank.Teste.replace('_','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace(',','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('@','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('#','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('  ','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace(':','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('\"','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('rt','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('\\\\*','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('\\*','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('\\$','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('\\n','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('//','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace(';','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('/','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('\\(','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('\\)','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('\\'','',regex=True)\n",
    "nubank.Teste = nubank.Teste.replace('!','',regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>Maquina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oi bbsalguém me envia um convite do nubankobri...</td>\n",
       "      <td>r</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nubankbrasil diga olá para uma vida livre de ...</td>\n",
       "      <td>ir</td>\n",
       "      <td>ir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eliezer94589997 vc pode pedir através de nosso...</td>\n",
       "      <td>r</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nubankbrasil diga olá para uma vida livre de ...</td>\n",
       "      <td>ir</td>\n",
       "      <td>ir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nubankbrasil unimos design e tecnologia para ...</td>\n",
       "      <td>ir</td>\n",
       "      <td>ir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste Relevancia Maquina\n",
       "0  oi bbsalguém me envia um convite do nubankobri...          r       r\n",
       "1   nubankbrasil diga olá para uma vida livre de ...         ir      ir\n",
       "2  eliezer94589997 vc pode pedir através de nosso...          r       r\n",
       "3   nubankbrasil diga olá para uma vida livre de ...         ir      ir\n",
       "4   nubankbrasil unimos design e tecnologia para ...         ir      ir"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando a lista relevantes\n",
    "relevantes = []\n",
    "for i in range(len(nubank.Teste)):\n",
    "    relevantes.append(bayes(nubank.Teste[i]))\n",
    "    \n",
    "\n",
    "#Adicionando a coluna Maquina do dataFrame\n",
    "nubank.Maquina = pd.Series(relevantes)\n",
    "nubank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Analisando a performance\n",
    "p = []\n",
    "for i in range(len(nubank.Teste)):\n",
    "    if nubank.Relevancia[i] == 'r':\n",
    "        if nubank.Maquina[i] == 'r':\n",
    "            p.append('PV')\n",
    "        if nubank.Maquina[i] == 'ir':\n",
    "            p.append('NF')\n",
    "    elif nubank.Relevancia[i] == 'ir':\n",
    "        if nubank.Maquina[i] == 'ir':\n",
    "            p.append('NV')\n",
    "        if nubank.Maquina[i] == 'r':\n",
    "            p.append('PF')\n",
    "#Criando serie de acertos\n",
    "acertos = pd.Series(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos Falsos: 2.5%\n",
      "Positivos Verdadeiros: 53.0%\n",
      "Negativos Verdadeiros: 40.5%\n",
      "Negativos Falsos: 4.0%\n"
     ]
    }
   ],
   "source": [
    "pf = p.count('PF')/2\n",
    "pv = p.count('PV')/2\n",
    "nf = p.count('NF')/2\n",
    "nv = p.count('NV')/2\n",
    "\n",
    "print(\"Positivos Falsos: {0}%\\nPositivos Verdadeiros: {1}%\\nNegativos Verdadeiros: {2}%\\nNegativos Falsos: {3}%\".format(pf,pv,nv,nf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Conclusão\n",
    "\n",
    "Ao iniciarmos o projeto, houve duvida sobre proceder com o uso da biblioteca Pandas ou com listas, portanto fizemos dos dois jeitos (existem dois arquivos jupyter notebook no git). Decidimos usar esse pois ao compararmos os Positivos e Negativos Verdadeiros, conseguimos chegar a um resultado mais preciso usando a biblioteca.\n",
    "Como podemos ver nos resultados acima, temos uma precisão de 93,5% de acertos na classificação de tweets, mas mesmo assim encontramos dois problemas principais para realizar o Classificador pela Teoria de Bayes:\n",
    "\n",
    "* Mensagens sarcasticas ou com dupla negação, que são tratadas como qualquer outra, fazendo com que não se encaixem na teoria, já que esta nao reconhece subjetividade nas mensagens. Ao digitar duas vezes a palavra \"não\", por exemplo, o sistema simplesmente reconhece as duas palavras independentemente de sua correlação.\n",
    "* Definir o tamanho dos dados utilizados para treinamento, pois como o projeto foi apenas um teste, não pudemos expandir a base de dados inicial para fazer o Classificador. Quanto maior for a base de dados inicial, maior será a precisão que teremos no resultado final, pois teremos mais informações sobre a interação das palavras.\n",
    "\n",
    "Se aprovado, o projeto já tem um plano de expansão definido, que consistiria em expandir a base de Treinamento e fazer com que o programa passe a reconhecer dentro de tweets elementos como dupla negação e outros que tornariam a classificação dos tweets mais precisa e personalizada para o desenvolvimento do produto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
